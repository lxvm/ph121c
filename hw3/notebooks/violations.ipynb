{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e786cd08-517f-4ce5-a2cc-314f5271f94b",
   "metadata": {},
   "source": [
    "# Violations of ETH\n",
    "\n",
    "$\n",
    "\\require{physics}\n",
    "\\def\\bm{\\boldsymbol}\n",
    "$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a586f2f-8ea6-4c99-83af-7c8657c0225c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import optimize\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from ph121c_lxvm import models, data, basis, measure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a471570-05d6-4c9f-9ed7-4f79b2bac3b9",
   "metadata": {},
   "source": [
    "## Many-body localized model\n",
    "\n",
    "We introduce disorder to the model we have used before by allowing random\n",
    "coefficients:\n",
    "$$\n",
    "    H = \\sum_{j=1}^L \\sigma_j^z \\sigma_{j+1}^z\n",
    "    - \\sum_{j=1}^L h_j^x \\sigma_j^x\n",
    "    - \\sum_{j=1}^L h_j^z \\sigma_j^z \n",
    "    .\n",
    "$$\n",
    "The random coefficients $h_j^x$ and $h_j^z$ are sampled uniformly from $[W, W]$,\n",
    "where the magnitude of $W$ determines the strength of the random noise.\n",
    "This model may introduce localization of the quantum state, where the random\n",
    "noise causes the probability mass to focus on some sites in the chain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c657f1-419a-48f1-ac72-3936186e51f3",
   "metadata": {},
   "source": [
    "### Repeating dynamical ETH experiments\n",
    "\n",
    "Here we're just going to repeat a lot of the code from before to create the\n",
    "same graphics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a1a8c1-dc32-44c2-9e55-223dc557d81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Def variables and time evolve expectation values\n",
    "save = '../../data/randoms.pick'\n",
    "xi = np.array([-np.sqrt(3), 1]) * 0.5    \n",
    "dt = 0.05\n",
    "Nstp = 1000\n",
    "W = 3.0\n",
    "Navg = 5\n",
    "bc = 'c'\n",
    "opers = ['x', 'y', 'z']\n",
    "graphs = [8, 10, 12]\n",
    "\n",
    "\n",
    "try:\n",
    "    df = pd.read_pickle(save)\n",
    "except FileNotFoundError:\n",
    "    \n",
    "    randoms = {\n",
    "        'Pauli' : [],\n",
    "        'vals' : [],\n",
    "        'L' : [],\n",
    "        'i' : [],\n",
    "    }\n",
    "\n",
    "    \n",
    "    rng = np.random.default_rng(seed=935)\n",
    "\n",
    "    for L in graphs:\n",
    "        psi = 1\n",
    "        for i in range(L):\n",
    "            psi = np.kron(xi, psi)\n",
    "        for i in range(Navg):\n",
    "            job = dict(\n",
    "                oper=models.tfim_z.H_dense,\n",
    "                oper_params={\n",
    "                    'L' : L,\n",
    "                    'h' : rng.uniform(low=-W, high=W, size=L),\n",
    "                    'hz': rng.uniform(low=-W, high=W, size=L),\n",
    "                    'bc': bc,\n",
    "                },\n",
    "                solver=np.linalg.eigh,\n",
    "                solver_params={},\n",
    "            )\n",
    "            evals, evecs = data.jobs.obtain(**job)\n",
    "\n",
    "            coef = evecs.T @ psi\n",
    "            for which in opers:\n",
    "                cevecs = (coef * evecs).T.astype('complex')\n",
    "                tevals = np.exp(-1j*dt*evals)\n",
    "                randoms['L'].append(L)\n",
    "                randoms['i'].append(i)\n",
    "                randoms['Pauli'].append(which)\n",
    "                randoms['vals'].append(\n",
    "                    measure.evolve.Pauli_ev(\n",
    "                        L=L, Nstp=Nstp, which=which, cevecs=cevecs, tevals=tevals,\n",
    "                        num_threads=4\n",
    "                    )\n",
    "                )\n",
    "\n",
    "    df = pd.DataFrame(randoms)\n",
    "    df.to_pickle(save)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f713f668-fca0-4edb-8f02-0388c3791492",
   "metadata": {},
   "source": [
    "The original run time was:\n",
    "```\n",
    "CPU times: user 1h 36min 47s, sys: 16 s, total: 1h 37min 3s\n",
    "Wall time: 8min 25s\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2187ff6-d6fa-4133-b887-b24847066fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Here we repeat the calculations to get the thermal values\n",
    "zzz = lambda x: np.exp(-x * evals)\n",
    "zz  = lambda x: sum(evals * zzz(x))\n",
    "z   = lambda x: sum(zzz(x))\n",
    "\n",
    "energies = []\n",
    "roots = []\n",
    "observe = dict(x=[], y=[], z=[])\n",
    "\n",
    "nrow = 2\n",
    "ncol = 2\n",
    "\n",
    "rng = np.random.default_rng(seed=935)\n",
    "\n",
    "for L in graphs:\n",
    "    for i in range(Navg):\n",
    "        hx = rng.uniform(low=-W, high=W, size=L)\n",
    "        hz = rng.uniform(low=-W, high=W, size=L)\n",
    "        job = dict(\n",
    "            oper=models.tfim_z.H_dense,\n",
    "            oper_params={\n",
    "                'L' : L,\n",
    "                'h' : hx,\n",
    "                'hz': hz,\n",
    "                'bc': bc,\n",
    "            },\n",
    "            solver=np.linalg.eigh,\n",
    "            solver_params={},\n",
    "        )\n",
    "        evals, evecs = data.jobs.obtain(**job)\n",
    "        # Build inital state\n",
    "        psi = 1\n",
    "        for _ in range(L):\n",
    "            psi = np.kron(xi, psi)\n",
    "        assert np.allclose(np.linalg.norm(psi), 1)\n",
    "        energies.append(\n",
    "            np.inner(psi, models.tfim_z.H_vec(psi, L, hx, bc, hz))\n",
    "        )\n",
    "        # Find which beta gives energy of psi\n",
    "        roots.append(\n",
    "            optimize.root_scalar(\n",
    "                lambda x: zz(x) / z(x) + abs(energies[-1]),\n",
    "                bracket=[1e-5, 10], method='brentq'\n",
    "            ).root\n",
    "        )\n",
    "        # Build thermal state\n",
    "        therm = np.exp(-roots[-1] * evals)\n",
    "        therm = therm / sum(therm)\n",
    "        # Normalize!\n",
    "        therm = therm / np.linalg.norm(therm)\n",
    "        # Calculate expectation values\n",
    "        for which in opers:\n",
    "            cevecs = (therm * evecs).T.astype('complex')\n",
    "            tevals = np.zeros(2 ** L, dtype='complex')\n",
    "            observe[which].append(\n",
    "                measure.evolve.Pauli_ev(\n",
    "                    L=L, Nstp=1, which=which, cevecs=cevecs, tevals=tevals,\n",
    "                    num_threads=4\n",
    "                )\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee623c5a-aada-4cc4-b2ce-445e1bb89ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nrow = len(graphs)\n",
    "ncol = len(opers)\n",
    "fig, axes = plt.subplots(nrow, ncol)\n",
    "for i, row in enumerate(axes):\n",
    "    for j, ax in enumerate(row):\n",
    "        for k in range(Navg):\n",
    "            ax.plot(\n",
    "                np.arange(Nstp)*dt,\n",
    "                df[(df.Pauli == opers[j]) & (df.L == graphs[i]) & (df.i == k)\n",
    "                ].vals.values[0], alpha=0.3\n",
    "            )\n",
    "        ax.plot(\n",
    "            np.arange(Nstp)*dt,\n",
    "            np.mean(df[(df.Pauli == opers[j]) & (df.L == graphs[i])].vals.values)\n",
    "        )\n",
    "        ax.axhline(np.mean(observe[opers[j]][i*Navg:(i+1)*Navg]))\n",
    "        ax.set_title(f\"$\\sigma_0^{opers[j]}, L={graphs[i]}$\")\n",
    "        ax.set_xlabel('t')\n",
    "        ax.set_ylabel(f\"$\\\\langle \\sigma_0^{opers[j]} (t) \\\\rangle$\")\n",
    "fig.set_size_inches(9, 9)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8058ba7-9e5a-4324-9a12-65b47bffe8a0",
   "metadata": {},
   "source": [
    "There are 5 realizations of the noise. It looks pretty to see all of them dancing\n",
    "about unitarily. Most of them seem to be converging to the same value, especially\n",
    "$\\sigma^z$ for larger $L$, though it seems like some of the realizations are\n",
    "happy doing their own thing.\n",
    "\n",
    "The plot displays all of the realizations as translucent traces, whereas the\n",
    "solid brown trace is the average of all the traces.\n",
    "The horizontal line is the average of the thermal expectation values over the\n",
    "realizations.\n",
    "\n",
    "I'm pretty sure I've made some mistakes leading to discrepancies between the\n",
    "long-time value of the two solid lines.\n",
    "I ran into an issue which I tried to patch: the issue was that some of the\n",
    "states had positive energy expectation values, so I couldn't solve for the\n",
    "inverse temperature because those energies are strictly negative.\n",
    "My patch was to flip the sign.\n",
    "\n",
    "Alas!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fdb7780-5c5d-47ab-9f33-7afff0f3c927",
   "metadata": {},
   "source": [
    "### Half-chain entanglement entropy ... again\n",
    "\n",
    "Same two states as the previous part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be367279-a91d-4bc3-9be7-9f787cb5843e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "om = np.array([-np.pi, np.e]) / np.sqrt(np.e ** 2 + np.pi ** 2)\n",
    "\n",
    "entropx = dict(L=[], t=[], psi=[], phi=[], i=[])\n",
    "\n",
    "dt = 0.1\n",
    "Nstp = 60\n",
    "\n",
    "rng = np.random.default_rng(seed=935)\n",
    "\n",
    "for L in graphs:\n",
    "    for i in range(Navg):\n",
    "        hx = rng.uniform(low=-W, high=W, size=L)\n",
    "        hz = rng.uniform(low=-W, high=W, size=L)\n",
    "        job = dict(\n",
    "            oper=models.tfim_z.H_dense,\n",
    "            oper_params={\n",
    "                'L' : L,\n",
    "                'h' : hx,\n",
    "                'hz': hz,\n",
    "                'bc': bc,\n",
    "            },\n",
    "            solver=np.linalg.eigh,\n",
    "            solver_params={},\n",
    "        )\n",
    "        evals, evecs = data.jobs.obtain(**job)\n",
    "        tevals = np.exp(-1j * evals * dt)\n",
    "        # Build inital state\n",
    "        psi = 1\n",
    "        phi = 1\n",
    "        for _ in range(L):\n",
    "            psi = np.kron(xi, psi)\n",
    "            phi = np.kron(om, phi)\n",
    "        assert np.allclose(np.linalg.norm(psi), 1)\n",
    "        assert np.allclose(np.linalg.norm(phi), 1)\n",
    "        # change to energy basis\n",
    "        psi = evecs.T @ psi\n",
    "        phi = evecs.T @ phi\n",
    "        for j in range(Nstp):\n",
    "            # measure\n",
    "            entropx['L'].append(L)\n",
    "            entropx['t'].append(j*dt)\n",
    "            entropx['i'].append(i)\n",
    "            entropx['psi'].append(\n",
    "                measure.entropy.entanglement(basis.schmidt.values(\n",
    "                        evecs @ psi, np.arange(L // 2), L\n",
    "                    ))\n",
    "            )\n",
    "            entropx['phi'].append(\n",
    "                measure.entropy.entanglement(basis.schmidt.values(\n",
    "                        evecs @ phi, np.arange(L // 2), L\n",
    "                    ))\n",
    "            )\n",
    "            # propagate\n",
    "            psi = tevals * psi\n",
    "            phi = tevals * phi\n",
    "\n",
    "    df = pd.DataFrame(entropx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6e250d-9852-417d-aecc-9b6b94a0f3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, sharey=True)\n",
    "grp = df.groupby(['L', 't']).mean().reset_index()\n",
    "for i, L in enumerate(graphs):\n",
    "    for j, which in enumerate(['phi', 'psi']):\n",
    "        # psi\n",
    "        axes[j].plot(\n",
    "            grp[grp.L == L].t.values,\n",
    "            grp[grp.L == L][which].values / L,\n",
    "            label=f'$L={L}$'\n",
    "        )\n",
    "        axes[j].set_title('$\\\\psi$')\n",
    "        axes[j].set_xlabel('$t$')\n",
    "        axes[j].legend()\n",
    "axes[0].set_ylabel('$S_{L/2}/L$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625838b2-8ef0-45d6-956e-20c439e9274f",
   "metadata": {},
   "source": [
    "As usual, the entropy is increasing with time.\n",
    "Here we've averaged over the realizations of the Hamiltonian.\n",
    "Bad idea to use MPS, but who knows?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2362a156-6344-4918-8ac2-9a514f25cead",
   "metadata": {},
   "source": [
    "### Eigenstate ETH again\n",
    "\n",
    "Let's observe the features of the same observables in the energy basis.\n",
    "I checked that there were no momentum sectors too. Instead we should do the calculation for some meaningfull subset of the eigenvectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8131bc1-4e33-46db-923a-7646d7d0e685",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "bc = 'c'\n",
    "sizes = [8, 10, 12]\n",
    "opers = ['x', 'y', 'z']\n",
    "values = {\n",
    "    'Pauli' : [],\n",
    "    'vals' : [],\n",
    "    'L' : [],\n",
    "    'E' : [],\n",
    "    'n' : [],\n",
    "    'k' : [],\n",
    "}\n",
    "entropx = dict(L=[], S=[], E=[], n=[], k=[])\n",
    "\n",
    "rng = np.random.default_rng(seed=935)\n",
    "\n",
    "for L in sizes:\n",
    "    for k in range(Navg):\n",
    "        hx = rng.uniform(low=-W, high=W, size=L)\n",
    "        hz = rng.uniform(low=-W, high=W, size=L)\n",
    "        job = dict(\n",
    "            oper=models.tfim_z.H_dense,\n",
    "            oper_params={\n",
    "                'L' : L,\n",
    "                'h' : hx,\n",
    "                'hz': hz,\n",
    "                'bc': bc,\n",
    "            },\n",
    "            solver=np.linalg.eigh,\n",
    "            solver_params={},\n",
    "        )\n",
    "        evals, evecs = data.jobs.obtain(**job)\n",
    "\n",
    "        # Now calculate expectation values\n",
    "        for i, _ in enumerate(evals):\n",
    "            # only look at 100 eigenstates to save time\n",
    "            if i % (evals.size // 100) == 0:\n",
    "                for which in opers:\n",
    "                    tevals = np.zeros(2 ** L, dtype='complex')\n",
    "                    tevals[i] = 1\n",
    "                    cevecs = (tevals * evecs).T.astype('complex')\n",
    "                    values['vals'].append(\n",
    "                        measure.evolve.Pauli_ev(\n",
    "                            L=L, Nstp=1, which=which, cevecs=cevecs, tevals=tevals,\n",
    "                            num_threads=4\n",
    "                        )[0]\n",
    "                    )\n",
    "                    values['k'].append(k)\n",
    "                    values['L'].append(L)\n",
    "                    values['n'].append(i)\n",
    "                    values['E'].append(evals[i])\n",
    "                    values['Pauli'].append(which)\n",
    "                entropx['k'].append(k)\n",
    "                entropx['L'].append(L)\n",
    "                entropx['n'].append(i)\n",
    "                entropx['E'].append(evals[i])\n",
    "                entropx['S'].append(\n",
    "                    measure.entropy.entanglement(basis.schmidt.values(\n",
    "                        evecs[:, i], np.arange(L // 2), L\n",
    "                    ))\n",
    "                )\n",
    "df = pd.DataFrame(values)\n",
    "dg = pd.DataFrame(entropx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d46def7-4ab4-4f33-8e7a-58d2a7168a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, len(opers))\n",
    "grp = df.groupby(['L', 'n', 'Pauli']).mean().reset_index()\n",
    "for i, ax in enumerate(axes):\n",
    "    for L in sizes:\n",
    "        ax.scatter(\n",
    "            grp[(grp.L == L) & (grp.Pauli == opers[i])].E.values / L,\n",
    "            grp[(grp.L == L) & (grp.Pauli == opers[i])].vals.values,\n",
    "            label=f'$L={L}$', alpha=0.8,\n",
    "        )\n",
    "    ax.set_title(f'$\\\\sigma_0^{opers[i]}$')\n",
    "    ax.set_xlabel('$\\\\epsilon_n / L$')\n",
    "    ax.set_ylabel('$\\\\langle \\\\sigma_0^{opers[i]} \\\\rangle_n$')\n",
    "    ax.legend()\n",
    "fig.set_size_inches(9, 6)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757040f9-80d6-4e5d-914d-e591032110c9",
   "metadata": {},
   "source": [
    "This data is much noisier than the eigenstate ETH Hamiltonian.\n",
    "It appears the there is much less correlation with energy\n",
    "in these expectation values of the eigenstates.\n",
    "In addition, the dependence on $L$ is unclear.\n",
    "For $\\sigma^z$, it appear that $L=10$ has a larger\n",
    "range than the others.\n",
    "I only obtained data points for 100 eigenstates, and each data point is an average over 5 realizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746a27e1-afd3-4860-85b9-27653db73be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "grp = dg.groupby(['L', 'n']).mean().reset_index()\n",
    "for L in sizes:\n",
    "    ax.scatter(\n",
    "        grp[grp.L == L].E.values / L,\n",
    "        grp[grp.L == L].S.values / L,\n",
    "        label=f'$L={L}$', alpha=0.8\n",
    "    )\n",
    "ax.set_title('Entanglement entropy')\n",
    "ax.set_xlabel('$\\\\epsilon_n / L$')\n",
    "ax.set_ylabel('$S_{L/2} / L$')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe35d5c-890f-4d58-8ea3-32ad3bd97af4",
   "metadata": {},
   "source": [
    "Here we can see that the entanglement entropies, averaged over 5 realizations, appear to separate,\n",
    "with some overlap, as a function of $L$.\n",
    "The same concave down pattern is observed as with the\n",
    "eigenstate ETH experiments, but the magnitude of the\n",
    "maximum is less by a factor of 2.\n",
    "However, this MBL model with noisy coefficients\n",
    "gives much noisier data.\n",
    "We still note that the MBL physics gives lower entropies per the eigenstates\n",
    "and that the observables all have mean zero, making the model on average contain less information, but the \n",
    "specific realizations have more conserved quantities and are less likely to thermalize."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5776819-8a02-4044-bd67-cb23c37c28eb",
   "metadata": {},
   "source": [
    "## Quantum many-body scar states\n",
    "\n",
    "The following Hamiltonian is a toy model of a loop of spin-1/2 Rydberg atoms:\n",
    "$$\n",
    "    H = \\frac{\\Omega}{2} \\sum_{j=1}^L \\sigma_j^x\n",
    "    + \\sum_{j=1}^L P_{j, j+1} \\sigma_{j+2}^z\n",
    "    ,\n",
    "$$\n",
    "where\n",
    "\\begin{align}\n",
    "    P_{j, j+1} \n",
    "        = (1 - \\bm \\sigma_j \\cdot \\bm \\sigma_{j+1}) / 4\n",
    "        = (1 - \\sigma_j^x \\sigma_{j+1}^x - \\sigma_j^y \\sigma_{j+1}^y - \\sigma_j^z \\sigma_{j+1}^z) / 4\n",
    "    .\n",
    "\\end{align}\n",
    "We are interested in this model because it contains scar states with unusually\n",
    "low entanglement entropy. These can be viewed as the quantum analog of periodic\n",
    "orbits in classically chaotic systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5181b22-33df-4f1d-94fd-5b88cbf4dc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "save = '../../data/scars.pick'\n",
    "try:\n",
    "    df = pd.read_pickle(save)\n",
    "except FileNotFoundError:\n",
    "\n",
    "    scars = {\n",
    "        'E' : [],\n",
    "        'S' : [],\n",
    "        'O' : [],\n",
    "        'L' : [],\n",
    "    }\n",
    "\n",
    "    for L, O in product([8, 10, 12], [0.0, 0.5, 1.0, 4.0]):\n",
    "\n",
    "        job = dict(\n",
    "            oper=models.scars.H_dense,\n",
    "            oper_params={\n",
    "                'L' : L,\n",
    "                'O' : O,\n",
    "            },\n",
    "            solver=np.linalg.eigh,\n",
    "            solver_params={},\n",
    "        )\n",
    "        evals, evecs = data.jobs.obtain(**job)\n",
    "\n",
    "        scars['L'].append(L)\n",
    "        scars['O'].append(O)\n",
    "        scars['E'].append(evals)\n",
    "        scars['S'].append([\n",
    "            # Evaluate entanglement entropy with respect to a half-subssystem\n",
    "            # To use a random subsystem instead of a contiguous one, use comments\n",
    "            # rng = np.random.default_rng(seed=935)\n",
    "            measure.entropy.entanglement(basis.schmidt.values(\n",
    "                evecs[:, i], np.arange(L//2), L\n",
    "            #     evecs[i], rng.choice(np.arange(L), size=L//2, replace=False), L\n",
    "            )) for i in range(evals.size)\n",
    "        ])\n",
    "        df = pd.DataFrame(scars)\n",
    "        df.to_pickle(save)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270a6792-a4df-4fcf-b034-686c6d421f4a",
   "metadata": {},
   "source": [
    "Original run time:\n",
    "```\n",
    "CPU times: user 1min 19s, sys: 948 ms, total: 1min 20s\n",
    "Wall time: 14.4 s\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0109bc-e064-4158-a723-4a22abff0c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nrow = 4\n",
    "ncol = 3\n",
    "fig, axes = plt.subplots(nrow, ncol, sharey=True)\n",
    "for i, row in enumerate(axes):\n",
    "    for j, ax in enumerate(row):\n",
    "        ax.scatter(\n",
    "            df.E[i + j*nrow] / df.L[i + j*nrow],\n",
    "            df.S[i + j*nrow] / df.L[i + j*nrow],\n",
    "            s=20, marker='x', alpha=0.4,\n",
    "        )\n",
    "        ax.set_title('$L=$' + str(df.L[i + j*nrow]) \\\n",
    "            + ', $\\Omega=$' + str(df.O[i + j*nrow]))\n",
    "        ax.set_ylabel('$S_{L/2}/L$')\n",
    "        ax.set_xlabel('$\\lambda/L$')\n",
    "        ax.vlines((df.O[i + j*nrow] / df.L[i + j*nrow]) \\\n",
    "            * (np.arange(df.L[i + j*nrow] + 1) - df.L[i + j*nrow] / 2),\n",
    "            ymin=0, ymax=0.3, linestyle='dotted',\n",
    "        )\n",
    "fig.set_size_inches(9, 9)\n",
    "fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd661f5c-096d-4133-a1c3-822f2c9af341",
   "metadata": {},
   "source": [
    "Look, there are scar states!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561244f5-1ac0-4504-8310-8053fc13196e",
   "metadata": {},
   "source": [
    "## Code snippets\n",
    "\n",
    "These are some useful code snippets I though I would drop here.\n",
    "I had made a few mistakes while indexing for calculations, so I though I'd\n",
    "give some code credit where it is due:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e06f772-f8c3-4ad3-a03f-7d5818c0ab1a",
   "metadata": {},
   "source": [
    "```python\n",
    "# Verify orthogonality of eigenvectors (this takes a while)\n",
    "for i, j in product(np.arange(evals.size), repeat = 2):\n",
    "    if i > j:\n",
    "        continue\n",
    "    elif i == j:\n",
    "        kron = 1\n",
    "    else:\n",
    "        kron = 0\n",
    "    assert np.allclose(kron, np.inner(evecs[:, i].conj(), evecs[:, j])), str(i) + ' ' + str(j)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f4c80e-e252-4e81-ab64-11a3d085f1d8",
   "metadata": {},
   "source": [
    "```python\n",
    "# Verify eigenpairs\n",
    "for i in range(evals.size):\n",
    "    assert np.allclose(models.scars.H_vec(evecs[:, i], L, O), evals[i] * evecs[:, i]), str(i)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14979428-fec7-4d4b-9a75-1d5b3d1db0e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
