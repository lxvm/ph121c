{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Image compression\n",
    "\n",
    "### Introduction\n",
    "\n",
    "I will be studying the singular value decomposition (SVD) of these images:\n",
    "\n",
    "<div>\n",
    "<img src=\"pictures/pic_1.png\" width=\"200\"/>\n",
    "<img src=\"pictures/pic_2.png\" width=\"200\"/>\n",
    "<img src=\"pictures/pic_3.png\" width=\"200\"/>\n",
    "</div>\n",
    "\n",
    "The image on the left is of the assignment.\n",
    "Henceforth, it is `pic_1.png`.\n",
    "Because we are doing SVD for this assignment, I thought it would be appropriate\n",
    "to do SVD on the assignment.\n",
    "Textual data may also provide a challenge for SVD, because rendering\n",
    "text well is a nontrivial task.\n",
    "\n",
    "The two images on the right come from my lab work on Se-Te nanostructures.\n",
    "These contain lamellar and circular patterns of different feature sizes.\n",
    "it will be interesting to see how their spectra compare to the text as well\n",
    "as how the reconstructions at various stages recapture the image quality.\n",
    "From left to right, these are `pic_2.png` and `pic_3.png`.\n",
    "\n",
    "### Program\n",
    "\n",
    "In the section below, we do the following for each image:\n",
    "- Read it into a grayscale array\n",
    "- Compute the Frobenius norm of the matrix (to use for comparisons)\n",
    "- Perform a singular value decomposition (SVD)\n",
    "- Reconstruct the image from the largest $10^{k+2} \\%$ of the singular values\n",
    "for $k \\in \\{-1, -2, -3\\}$\n",
    "- Compute the Frobenius distance of the approximation to the original\n",
    "- Save the reconstructed image\n",
    "\n",
    "We also:\n",
    "- Create a plot of the SVD spectrum\n",
    "- Save computed norms into a data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageOps\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_files(pathname, ext, n=0, out=''):\n",
    "    \"\"\"Outputs a generator of numbered strings 'folder/name[_i][_out].ext'\"\"\"\n",
    "    undr = lambda x, y: bool(x) * ('_' + str(y))\n",
    "    for i in range(n):\n",
    "        yield ''.join([pathname, undr(n, i+1), undr(out, out), '.', ext])\n",
    "\n",
    "def svd_rc(u, s, vh, n):\n",
    "    \"\"\"Reconstruct matrix using n largest principal values of svd\"\"\"\n",
    "    return u[:, :n] * s[:n] @ vh[:n, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture plot\n",
    "\n",
    "pic_path  = 'pictures/pic'\n",
    "pic_files = name_files(pic_path, 'png', 3)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "vals_og = { \n",
    "    'file' : [],\n",
    "    'Nval' : [],\n",
    "    'FroN' : [],\n",
    "}\n",
    "\n",
    "vals_rc = { \n",
    "    'file' : [],\n",
    "    'expo' : [],\n",
    "    'Nrec' : [],\n",
    "    'FroD' : [],\n",
    "}\n",
    "\n",
    "for i, pic_file in enumerate(pic_files):\n",
    "    # Convert image to grayscale array\n",
    "    img = Image.open(pic_file)\n",
    "    img = ImageOps.grayscale(img)\n",
    "    # Python feature: variables/pointers are not of fixed type\n",
    "    img = np.asarray(img)\n",
    "    # SVD of image\n",
    "    res = np.linalg.svd(img, full_matrices=False)\n",
    "    # Save total number of singular values and Frobenius norm of original\n",
    "    vals_og['file'].append(pic_file)\n",
    "    vals_og['Nval'].append(res[1].size)\n",
    "    vals_og['FroN'].append(np.linalg.norm(img))\n",
    "    # Plot spectrum normalized by array size and maximal principal value\n",
    "    ax.loglog(\n",
    "        np.arange(res[1].size) / res[1].size, \n",
    "        res[1] / np.max(res[1]), \n",
    "        label=pic_file,\n",
    "    )\n",
    "    for k in range(-3, 0):\n",
    "        out_file = ''.join([pic_path, '_', str(i+1), '_out_k=', str(k), '.png'])\n",
    "        # Reconstruct image from SVD with 10 ** k % of principal values\n",
    "        Npv = int(np.ceil((10 ** k) * res[1].size))\n",
    "        rec = svd_rc(*res, Npv)\n",
    "        # Save number of values used in reconstruction and Frobenius distance\n",
    "        vals_rc['file'].append(pic_file)\n",
    "        vals_rc['expo'].append(k)\n",
    "        vals_rc['Nrec'].append(Npv)\n",
    "        vals_rc['FroD'].append(np.linalg.norm(img - rec))\n",
    "        # Save reconstruction to file\n",
    "        rec = Image.fromarray(rec)\n",
    "        rec = ImageOps.grayscale(rec)\n",
    "        rec.save(out_file)\n",
    "\n",
    "df_og = pd.DataFrame(vals_og)\n",
    "df_rc = pd.DataFrame(vals_rc)\n",
    "        \n",
    "ax.set_ylim([1e-4, 1])\n",
    "ax.set_title('Singular value spectrum')\n",
    "ax.set_ylabel('Fraction of largest singular value')\n",
    "ax.set_xlabel('Quantile of singular values')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "#### Spectra\n",
    "\n",
    "I would first like to look at some features of the original images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_og"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each file, the `Nval` column the number singular of singular values used to\n",
    "decompose the original image, which is also the largest dimension of the image.\n",
    "Notably, `pic_1.png` has half as many singular values in the image as the\n",
    "other pictures because the image has half as many pixels in its largest dimension.\n",
    "Additionally, the `FroN` column computes the Frobenius norm of the image.\n",
    "On its own, the value doesn't mean much, but we will use it to normalize\n",
    "the Frobenius distance of reconstructions to compare for different images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rc['normFroD'] = df_rc.FroD / df_rc.file.replace(\n",
    "    { e : df_og.FroN[i] for i, e in enumerate(df_og.file) }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next thing I would like to study is the plot of the SVD spectra.\n",
    "Since very few images contain a great deal of high frequency data,\n",
    "I will use logarithmic scales on the plot to focus on the first, largest\n",
    "singular values.\n",
    "Additionally, I will normalize the values by diving the values on each axis\n",
    "by the largest in each array so that we can compare spectra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reconstructions\n",
    "\n",
    "##### `pic_1.png`\n",
    "\n",
    "Ordered from not compressed (left) to most compressed (right), the images are:\n",
    "\n",
    "<div>\n",
    "<img src=\"pictures/pic_1.png\" width=\"150\"/>\n",
    "<img src=\"pictures/pic_1_out_k=-1.png\" width=\"150\"/>\n",
    "<img src=\"pictures/pic_1_out_k=-2.png\" width=\"150\"/>\n",
    "<img src=\"pictures/pic_1_out_k=-3.png\" width=\"150\"/>\n",
    "</div>\n",
    "\n",
    "These reconstructions use the following parameters:\n",
    "- `expo`: The base-ten exponent representing the compression fraction\n",
    "- `Nrec`: The number of principal singular values used in the reconstruction\n",
    "- `FroD`: The Frobenius distance of the reconstruction from the original\n",
    "- `normFroD`: The value of `FroD` divided by `FroN` of the original image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rc[df_rc.file == 'pictures/pic_1.png']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `pic_2.png`\n",
    "\n",
    "Ordered from not compressed (left) to most compressed (right), the images are:\n",
    "\n",
    "<div>\n",
    "<img src=\"pictures/pic_2.png\" width=\"150\"/>\n",
    "<img src=\"pictures/pic_2_out_k=-1.png\" width=\"150\"/>\n",
    "<img src=\"pictures/pic_2_out_k=-2.png\" width=\"150\"/>\n",
    "<img src=\"pictures/pic_2_out_k=-3.png\" width=\"150\"/>\n",
    "</div>\n",
    "\n",
    "These reconstructions use the following parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rc[df_rc.file == 'pictures/pic_2.png']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `pic_3.png`\n",
    "\n",
    "Ordered from not compressed (left) to most compressed (right), the images are:\n",
    "\n",
    "<div>\n",
    "<img src=\"pictures/pic_3.png\" width=\"150\"/>\n",
    "<img src=\"pictures/pic_3_out_k=-1.png\" width=\"150\"/>\n",
    "<img src=\"pictures/pic_3_out_k=-2.png\" width=\"150\"/>\n",
    "<img src=\"pictures/pic_3_out_k=-3.png\" width=\"150\"/>\n",
    "</div>\n",
    "\n",
    "These reconstructions use the following parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rc[df_rc.file == 'pictures/pic_3.png']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "#### Spectra\n",
    "\n",
    "It is interesting that `pic_1.png`, which is very text based, has a spectrum\n",
    "that decays fastest (we might expect it to struggle with text).\n",
    "Across all the spectra, it is clear that due to the logarithmic scale, for all\n",
    "the images, the largest 10% of singular values are in the first thousandth of\n",
    "all the singular values.\n",
    "Since the images are less than 2000 pixels each in their largest dimension, this\n",
    "means that only one or two singular values dominate.\n",
    "\n",
    "Then it appears there is a gradually sloping region until about between 1 and 10\n",
    "% of all singular values, which would suggest an informative region, followed by\n",
    "a dip into another sloping region until after 10%, whereupon all the spectra \n",
    "dive down to very small magnitudes.\n",
    "So my choice of reconstruction based on 0.1%, 1% and 10% of all singular values\n",
    "seems to capture each of the regions of interest.\n",
    "\n",
    "Notably, the spectra of `pic_2.png` and `pic_3.png` appear very similar, which\n",
    "seems reasonable because the images are of very similar quality and morphology.\n",
    "\n",
    "#### Reconstructions\n",
    "\n",
    "Starting with `pic_1.png`, we can see that the reconstruction with 1 singular\n",
    "value is extremely blurry, but at least it captures the lines of text in the \n",
    "image.\n",
    "In the reconstruction with 9 values, it is possible to discern blocks that look\n",
    "like words, but there is no chance of reading them as the features like serifs\n",
    "of the font are mangled by linear approximations.\n",
    "Lastly, the 10% reconstruction appears readable, though of very low quality.\n",
    "The page is grainy and hard to read for any extended period of time, but the \n",
    "text is there and not very different than a low-quality scan of a document,\n",
    "especially compared with a scanner on a cell phone.\n",
    "\n",
    "In the reconstruction of `pic_2.png` with 2 singular values, the image looks\n",
    "like a quilt.\n",
    "Already with 1% of the values, the reconstruction has recover the \n",
    "\"spaghetti and cheerios\" morphology of the structure, though lacks the detail\n",
    "and accuracy of the final image.\n",
    "The 10% reconstruction has lower quality than the original, but is rather close\n",
    "to the original and would be acceptable.\n",
    "\n",
    "In the reconstruction of `pic_3.png` with 2 singular values, we again have a\n",
    "quilt, but can see that the decomposition discerns the big black hole at the\n",
    "center of the image as well as the presence of the scale bar at the bottom of\n",
    "the photograph.\n",
    "We can continue to say similar things as the second image because the features\n",
    "of the images are quite similar.\n",
    "On a higher quality close-up of the image, it is interest to look at what\n",
    "happens inside the \"black hole\" at the center of the image.\n",
    "In the full image, it is nearly dark, but in all of the reconstructions, there\n",
    "is high-frequency noise that sort of imposes the ghostly shadow of the\n",
    "lamellar pattern in the dark area.\n",
    "Without the less emphasized singular values, it is impossible to remove the\n",
    "more subtle defects of the image.\n",
    "\n",
    "It is also striking to compare the normalized Frobenius distance across the\n",
    "images.\n",
    "In general, the errors are nearly a factor of 2 smaller for `pic_1.png` than\n",
    "`pic_2` or `pic_3`, which are comparable approximations at each level of\n",
    "reconstruction.\n",
    "Because I have normalized these errors, I suspect the deviation is not due\n",
    "to the fact the first pictures has far fewer pixels to approximate, but\n",
    "because the norm doesn't care so much about the small details in the text.\n",
    "By comparison, some of the approximations that would be unacceptable for text\n",
    "are tolerable for the larger-scale patterns in the second and third pictures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
