\documentclass{article}
\linespread{1.075}
\usepackage{times}

\usepackage{physics}

\usepackage{listings}
\lstset{
    basicstyle=\ttfamily\footnotesize,
    numbers=left,
    frame=single,
}

\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    urlcolor=red,
}

\usepackage{graphicx}
\graphicspath{ {./include/plots} }

\begin{document}

{\centering

Ph 121c

Assignment 1

Lorenzo Van Munoz

\today

}

\tableofcontents

\newpage

\section{
Dense ED
}

The Transverse Field Ising Model (TFIM) for a spin chain
of length $L$ with parameter $h$ is given by

\begin{align}
    \hat H = - \sum_{j=1}^{L-1} \hat \sigma^z_{j} \hat \sigma^z_{j+1} 
            - \qty( \hat \sigma^z_{L}  \hat \sigma^z_{1} )
            - h\sum_{j=1}^{L}  \hat \sigma^x_{j}.
\end{align}

I wrote two algorithms for initializing the dense Hamiltonian
corresponding to the TFIM: a direct construction by taking
tensor products (implied in $\hat H$ above) and a direct construction
for any vector by representing the Pauli operators
as bitwise operations computational basis (in binary).

Since the latter is less prone to memory allocation errors 
(unlike the former, it does not need to repeatedly sum large matrices
and does not use a recursive implementation) I was more comfortable
using it and will present some of its preliminary results.

\newpage

\section{
Sparse ED
}

Using intel MKL, I would have two routines for solving
sparse eigenvalue problems for real matrices:
{\tt ?feast_scsrev } for finding parts of a spectra, and
{\tt mkl_sparse_?_ev } for finding the extremal eigenvalues.
The former routine requires a 3-array CSR format, and the latter
requires the MKL Sparse BLAS CSR format, which is a 4-array format.
I will probably implement a function to do that later in the course,
because for this set I wrote my own Lanczos routine for finding extremal
eigenvalues, and it works beautifully with impressive speed.
Therefore, I circumvented the use sparse array formats because the algorithm
only needs a function that can multiply a vector by the Hamiltonian.
So I probably shouldn't call this section ``Sparse ED''.

I am able to push my Lanczos implementation to sizes of $L = 23$
for $m = 32$ eigenvalues, but not any more since $L = 24$ produces
critical errors at compilation time because it would require
$4 * 2^24 = 67,108,864$ bytes just to store one dense column of 
single-precision floats of size $2^24$, and clearly I would need
dozens of these for worker and output arrays, but I only have 16 Gb of RAM.

Here is an example of such a catastrophic compilation for $L=24, m=32$
\lstinputlisting{./include/catastrophic_compilation.txt}

Let's show how the algorithm's results compare to the dense solutions

Returning to the question of implementing sparse format at a later date,
I will be faced with two very different implementations that mirror
two very different implementations I made for the dense case.
If I go to tensor product route, I will have to find a way to tensor
product sparse matrices from scratch, in whatever format is needed.
If I go the bitwise route, I will have to find out how to put together
the sparse matrix one row at a time
In both cases, I will have to decide whether I consider using only a
symmetric representation or a full one.
In both cases, I will have to find a way to figure out the size of the
sparse matrix, ideally without ever creating the dense matrix, which
presents a problem with allocating the arrays for the sparse matrix
because I don't know their size apriori (hopefully without having to create 
a new array every time I need to add new elements).
Perhaps a linked list would work well to build the matrix, and then 
convert the linked list into an array.
The only thing I know is that the problem becomes
increasingly sparse in larger dimensions. 

\newpage

\section{
Convergence with system size
}



\newpage

\section{
Finding the quantum phase transition
}



\newpage

\section{
Magnetic ordering
}



\newpage

\section{
Using Ising symmetry
}



\newpage

\section{
Appendix: Code
}

All of my source code is available by viewing or cloning
\href{https://github.com/lxvm/ph121c.git}{this git repository}.

The remaining sections are a minimal reference for how the code
should be run and with what tools.

\subsection{
Computing environment
}

I am using the Intel oneAPI base toolkit (with MKL)
and HPC toolkit (with Fortran), which is freely available
\href{https://software.intel.com/content/www/us/en/develop/
articles/free-intel-software-developer-tools.html}{here}.
This is some information about my system and software:

\lstinputlisting{./include/versions.txt}

This pdf document was generated by latexmk using \TeX\ Live 2020.

\subsection{
Building this project
}

Please refer to the README's in the repository on how to compile the
code and generate the data presented in this document.

\end{document}
