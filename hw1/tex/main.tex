\documentclass{article}
\linespread{1.075}
\usepackage{times}

\usepackage{physics}

\usepackage{listings}
\lstset{
    basicstyle=\ttfamily\footnotesize,
    numbers=left,
    frame=single,
}

\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    urlcolor=red,
}

\usepackage{graphicx}
\graphicspath{ {./include/plots} }

\begin{document}

{\centering

Ph 121c

Assignment 1

Lorenzo Van Munoz

\today

}

\tableofcontents

\newpage

\section{
Dense ED
}

The Transverse Field Ising Model (TFIM) for a spin chain
of length $L$ with parameter $h$ (and zero indexed) is given by

\begin{align}
    \hat H = - \sum_{j=0}^{L-2} \hat \sigma^z_{j} \hat \sigma^z_{j+1} 
            - \qty( \hat \sigma^z_{L-1}  \hat \sigma^z_{0} )
            - h\sum_{j=0}^{L-1}  \hat \sigma^x_{j}.
\end{align}

I wrote two algorithms for initializing the dense Hamiltonian
corresponding to the TFIM: a direct construction by taking
tensor products (implied in $\hat H$ above) and a direct construction
for any vector by representing the Pauli operators
as bitwise operations computational basis (in binary).

Since the latter is less prone to memory allocation errors 
(unlike the former, it does not need to repeatedly sum large matrices
and does not use a recursive implementation) I was more comfortable
using it and will present some of its preliminary results.

\newpage

\section{
Sparse ED
}

Using intel MKL, I would have two routines for solving
sparse eigenvalue problems for real matrices:
{\tt ?feast\_scsrev } for finding parts of a spectra, and
{\tt mkl\_sparse\_?\_ev } for finding the extremal eigenvalues.
The former routine requires a 3-array CSR format, and the latter
requires the MKL Sparse BLAS CSR format, which is a 4-array format.
I will probably implement a function to do that later in the course,
because for this set I wrote my own Lanczos routine for finding extremal
eigenvalues, and it works beautifully with impressive speed.
Therefore, I circumvented the use sparse array formats because the algorithm
only needs a function that can multiply a vector by the Hamiltonian.
So I probably shouldn't call this section ``Sparse ED''.

I am able to push my Lanczos implementation to sizes of $L = 23$
for $m = 32$ eigenvalues, but not any more since $L = 24$ produces
critical errors at compilation time because it would require
$4 * 2^24 = 67,108,864$ bytes (B) just to store one dense column of 
single-precision floats of size $2^{24}$, and clearly I would need
dozens of these for worker and output arrays, but I only have 16 GB of RAM.

Here is an example of such a catastrophic compilation for $L=24, m=32$
\lstinputlisting{./include/catastrophic_compilation.txt}

Let's show how the algorithm's results compare to the dense solutions

Returning to the question of implementing sparse format at a later date,
I will be faced with two very different implementations that mirror
two very different implementations I made for the dense case.
If I go to tensor product route, I will have to find a way to tensor
product sparse matrices from scratch, in whatever format is needed.
If I go the bitwise route, I will have to find out how to put together
the sparse matrix one row at a time
In both cases, I will have to decide whether I consider using only a
symmetric representation or a full one.
In both cases, I will have to find a way to figure out the size of the
sparse matrix, ideally without ever creating the dense matrix, which
presents a problem with allocating the arrays for the sparse matrix
because I don't know their size apriori (hopefully without having to create 
a new array every time I need to add new elements).
Perhaps a linked list would work well to build the matrix, and then 
convert the linked list into an array.
The only thing I know is that the problem becomes
increasingly sparse in larger dimensions. 

\newpage

\section{
Convergence with system size
}



\newpage

\section{
Finding the quantum phase transition
}



\newpage

\section{
Magnetic ordering
}



\newpage

\section{
Using Ising symmetry
}

To transfer from the $z$ basis, $\{\ket{\uparrow}, \ket{\downarrow} \}$,
to the $x$ basis, $\{\ket{+}, \ket{-}\}$, use this operator
\begin{align}
    \hat T = \frac{1}{\sqrt{2}} \mqty( 1 & 1 \\ 1 & -1 ).
\end{align}
Notably, $T$ is its own inverse. 
Rotating the Hamiltonian does the following:
\begin{align}
    \hat H_z \ket{\psi}_z
        \to& \qty( \prod_j \hat T_j ) \hat H_z \ket{\psi}_z
    \\
    &= \qty( \prod_j \hat T_j ) \hat H_z \qty( \prod_j \hat T_j )
        \qty( \prod_j \hat T_j ) \ket{\psi}_z 
    \\
    &= \hat H_x \ket{\psi}_x.
\end{align}
The form of $H_x$ is as follows:
\begin{align}
    \hat H_x =& \qty( \prod_j \hat T_j ) \hat H_z \qty( \prod_j \hat T_j )
    \\
    =& \qty( \prod_j \hat T_j )
        \qty( -\sum_{j=0}^{L-2} \hat \sigma^z_{j} \hat \sigma^z_{j+1} 
            - \hat \sigma^z_{L-1} \hat \sigma^z_{0}
            -h \sum_{j=0}^{L-1} \hat \sigma^x_{j})
        \qty( \prod_j \hat T_j )
    \\
    =& -\sum_{j=0}^{L-2} \hat T_j \hat \sigma^z_{j} \hat T_j
                        \hat T_{j+1} \hat \sigma^z_{j+1} \hat T_{j+1}
        - \hat T_{L-1} \hat \sigma^z_{L-1} \hat T_{L-1} 
             \hat T_{0}  \hat \sigma^z_{0} \hat T_{0} 
        -h \sum_{j=0}^{L-1}  \hat T_{j} \hat \sigma^x_{j} \hat T_{j}
    \\
    =& -\sum_{j=0}^{L-2} \hat \sigma^x_{j} \hat \sigma^x_{j+1}
        - \hat \sigma^x_{L-1} \hat \sigma^x_{0} 
        -h \sum_{j=0}^{L-1}  \hat \sigma^z_{j}.
\end{align}
This effectively interchanges the role of the sign-flip and spin-flip operators.
(Sorry if the notation is confusing: the Hamiltonian is in the $x$ basis but
the Pauli matrices still have the same matrix elements as in the $z$ basis)

With this form of the Hamiltonian, we are one permutation away from expressing
the disjoint symmetry sectors as a Hamiltonian in block diagonal form, with each
block acting on its own parity sector.
Recall the parity operator 
\begin{align}
    \hat U_z = \prod_j \hat \sigma_{j}^x
\end{align}
which in the x basis is diagonal:
\begin{align}
    \hat U_x = \prod_j \hat \sigma_{j}^z.
\end{align}

Notice how if we zero-index the basis states in the $x$ basis by integers,
the parity operator is the same as the parity of the bit string of the integer
if we take the bit parity of zero to correspond to + eigenstates 
and the bit parity of one to correspond to - eigenstates.
So in order to separate the $x$ basis, we just need an efficient way to flip
bit strings that acts as a permutation of $\hat H_x$ to transform it into block
diagonal form.

Fix $L$ and let $\ket{+_j}, \ket{-_j}$ denote the $j$-th basis element of the
$x$ basis in the + and - parity sectors, respectively 
(Note there are $2^{L-1}$ states in each sector).
Let's zero index these states and find a bit operator map that sends the index
$j$ to the $k$th element of the computational $x$ basis, whose Hamiltonian,
$\hat H_x$, we know.
Note we also need the inverse permutation in order to correctly reassign the
action of terms of the Hamiltonian.

One way to do this is to calculate the diagonal entries of $\hat U_x$, 
and to store an array which in the $j$-th index has the value $k$.
The reverse map is obtained by placing $j$ in the $k$-th entry of the
array which was the diagonal of $\hat U_x$
The diagonal of $\hat U_x$ can be constructed recursively as follows:
let $b_j$ be a bit string of length $2^j$, starting with $b_1 = \qty( 0, 1 )$,
and obtain $b_{j+1}$ by concatentation: $b_{j+1} = \mqty( b_j, -b_j)$, where
a minus sign denotes a bitwise flip operator.

Note that the $k$th entry of $b_j$ is the bit string parity of $k$ (zero indexed).
The first few bit strings are:
\begin{align}
    b_1 =& (0, 1)
    \\
    b_2 =& (0, 1, 1, 0)
    \\
    b_3 =& (0, 1, 1, 0, 1, 0, 0, 1)
\end{align}
which translates to the following diagonal entries of $\hat U_x$:
\begin{align}
    \qty(\hat U_x)^{L=1}_{ii} =& (1, -1)
    \\
    \qty(\hat U_x)^{L=2}_{ii} =& (1, -1, -1, 1)
    \\
    \qty(\hat U_x)^{L=3}_{ii} =& (1, -1, -1, 1, -1, 1, 1, -1).
\end{align}
Thus these indices provide all the bookkeeping necessary to take the symmetry sectors
into a block diagonal form.

If you study this experimentally, perhaps using the {\tt parity\_diag} function
I wrote in the {\tt tfim\_dense} module, one finds that for states in $\mathcal H_+$
symmetry sector, the efficient bit operator that does the bookkeeping from the $j$-th
+ parity state to the $k$-th $x$ basis state is $k = 2*j + \epsilon(j)$ where $\epsilon$
is the bit string parity operator ($\epsilon(j) = 0$ if $j$ has an even number of 1's
and $\epsilon(j) = 1$ if $j$ has an odd number of 1's).
Likewise, for the $j$-th state in the - sector, it corresponds to $k = 2*j + (\epsilon^{-1}(j)$
(where $\epsilon^{-1}(j) = \epsilon(j+1)$).
The inverse operation in both cases is $j = (k - (k \% 2)) / 2$.
In Fortran:
\begin{lstlisting}[language=Fortran]
k = (2*j + poppar(j))           ! from + sector to full basis
k = (2*j + (1 .xor. poppar(j))  ! from - sector to full basis
j = (k - mod(k, 2)) / 2         ! Inverse in both sectors
\end{lstlisting}

\newpage

\section{
Appendix: Code
}

All of my source code is available by viewing or cloning
\href{https://github.com/lxvm/ph121c.git}{this git repository}.

The remaining sections are a minimal reference for how the code
should be run and with what tools.

\subsection{
Computing environment
}

I am using the Intel oneAPI base toolkit (with MKL)
and HPC toolkit (with Fortran), which is freely available
\href{https://software.intel.com/content/www/us/en/develop/
articles/free-intel-software-developer-tools.html}{here}.
This is some information about my system and software:

\lstinputlisting{./include/versions.txt}

This pdf document was generated by latexmk using \TeX\ Live 2020.

\subsection{
Building this project
}

Please refer to the README's in the repository on how to compile the
code and generate the data presented in this document.

\end{document}
